{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64d60d94",
      "metadata": {
        "id": "64d60d94"
      },
      "source": [
        "### Task: Sentiment Classification of Movie Reviews  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MnFtJo_vQ7fd",
      "metadata": {
        "id": "MnFtJo_vQ7fd"
      },
      "source": [
        "Alice is a time traveler who visits different eras in the past to solve important missions. While there, she must always be careful to disguise herself so that no one will know she is from the future. This time, she joined an NLP company in 2014 year and was assigned the task of sentiment analysis on user reviews for movies. Help Alice with this task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09CmnLTit1a0",
      "metadata": {
        "id": "09CmnLTit1a0"
      },
      "source": [
        "You need to solve sentiment classification task using the imdb movie review dataset. Each review is labeled as either positive (1) or negative (0), indicating its sentiment. You will be provided by basic LinearSVC classifier with TF-IDF features.\n",
        "\n",
        "You need to solve 3 tasks:\n",
        "\n",
        "1.   Task1: Text Preprocessing with spaCy (this is your baseline)\n",
        "2.   Task 2: Adding Part-of-Speech (POS) Features as a TF-IDF for Each POS Category\n",
        "3.   Task 3: Development of new features to improve classification accuracy\n",
        "\n",
        "**Note!** Do not change the classifier. Change only cells with TODO mark.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995ac04c",
      "metadata": {
        "id": "995ac04c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import (\n",
        "    TfidfVectorizer,\n",
        "    CountVectorizer,\n",
        ")\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e83541ef",
      "metadata": {
        "id": "e83541ef"
      },
      "outputs": [],
      "source": [
        "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e40afc00",
      "metadata": {
        "id": "e40afc00"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e_6CBdQXOD1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e_6CBdQXOD1",
        "outputId": "21159c9c-c9ae-41d0-9f57-faa02f41a766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1C6TIP8c33fHM6dxs6DoxJeKY6ZXGWpBx\n",
            "To: /content/imdb_train_hw1.csv\n",
            "100% 8.25M/8.25M [00:00<00:00, 29.7MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K8WBFVVvVlsvIMRG8HiaFkldiyuNkLD2\n",
            "To: /content/imdb_test_hw1.csv\n",
            "100% 2.10M/2.10M [00:00<00:00, 165MB/s]\n"
          ]
        }
      ],
      "source": [
        "! gdown --id 1C6TIP8c33fHM6dxs6DoxJeKY6ZXGWpBx\n",
        "! gdown --id 1K8WBFVVvVlsvIMRG8HiaFkldiyuNkLD2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808c6df4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "808c6df4",
        "outputId": "4f170881-82d1-4ffc-ba56-91fb74056ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  label                                               text\n",
              "8681        8681      1  I noticed this movie was getting trashed well ...\n",
              "2362        2362      1  When it comes to creating a universe George Lu...\n",
              "6232        6232      0  \"National Treasure\" (2004) is a thoroughly mis...\n",
              "1318        1318      1  I must admit - the only reason I bought this m...\n",
              "543          543      1  Ten out of the 11 short films in this movie ar..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98462535-7393-4e5a-bdb9-fc231c181945\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8681</th>\n",
              "      <td>8681</td>\n",
              "      <td>1</td>\n",
              "      <td>I noticed this movie was getting trashed well ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2362</th>\n",
              "      <td>2362</td>\n",
              "      <td>1</td>\n",
              "      <td>When it comes to creating a universe George Lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6232</th>\n",
              "      <td>6232</td>\n",
              "      <td>0</td>\n",
              "      <td>\"National Treasure\" (2004) is a thoroughly mis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1318</th>\n",
              "      <td>1318</td>\n",
              "      <td>1</td>\n",
              "      <td>I must admit - the only reason I bought this m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>543</td>\n",
              "      <td>1</td>\n",
              "      <td>Ten out of the 11 short films in this movie ar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98462535-7393-4e5a-bdb9-fc231c181945')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98462535-7393-4e5a-bdb9-fc231c181945 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98462535-7393-4e5a-bdb9-fc231c181945');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-262f6921-186b-4155-bbb2-f0d2ea72a77a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-262f6921-186b-4155-bbb2-f0d2ea72a77a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-262f6921-186b-4155-bbb2-f0d2ea72a77a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3484,\n        \"min\": 543,\n        \"max\": 8681,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2362,\n          543,\n          6232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"When it comes to creating a universe George Lucas is the undisputed master and his final Star Wars film is very, very good (and more appropriately rated in comparison to the two previous films in the original saga). Having recently seen Revenge of the Sith really puts this movie in perspective. The final battle seems even more climactic knowing what Anakin Skywalker went through at the manipulative hands of the Emperor. It also makes the final battle between Luke and Vader more bitter considering the love he felt for Padm\\u00e9 and the love she felt for her children. Actually while the new films (especially Episode II) are inferior to the original films they are good for one reason only.\",\n          \"Ten out of the 11 short films in this movie are masterpieces (I found only the Egyptian one disappointing). Stragely, all but the Mexican director chose to portray the problems of individuals or groups in connection with 9-11: the Afghan refugees, deaf people, Palestinians, the widows of Srebrenica, AIDS and poverty and corruption in Africa, Pinochets coup and ensuing bloodbath, suicide bombings in Israel, paranoia-hit and state-persecuted Muslim Americans in the USA, old people living alone, and the aftermath of WWII in the hearts of Asian soldiers. This might say something sad about the limits of empathy, in both ways: the directors might feel that Americans ignore the pains of the rest of the world and only care about their own tragedies, while they effectively do the same with their short films.<br /><br />Surprising myself, I found Sean Penn's piece one of the very best in the collection, and ***SPOILER AHEAD*** I also guess his portrayal of Ernest Borgnine as a half-crazy old man vegetating in a New York flat experiencing his widow life's happiest moment when the Sun shines through his window after the WTC \\\"collapsed out of light's way\\\", I guess this might also be one of the most offending as the general American audience would see it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_train = pd.read_csv(\"imdb_train_hw1.csv\")\n",
        "df_test = pd.read_csv(\"imdb_test_hw1.csv\")\n",
        "df_train.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MkhanC2f0J5t",
      "metadata": {
        "id": "MkhanC2f0J5t"
      },
      "outputs": [],
      "source": [
        "y_train = df_train[\"label\"]\n",
        "y_test = df_test[\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe84f9a2",
      "metadata": {
        "id": "fe84f9a2"
      },
      "source": [
        "Since the classes in our dataset are nearly balanced, we can use accuracy as the evaluation metric. Accuracy provides a straightforward measure of how well the model classifies reviews correctly across both sentiment classes.  \n",
        "\n",
        "However, we will consider the F1-score for a more detailed performance assessment. Even with balanced classes, the model might still be biased towards one class due to feature distributions (e.g., it may predict negative reviews more confidently than positive ones).  \n",
        "\n",
        "The F1-score, which is the harmonic mean of precision and recall, helps us identify such imbalances. It ensures that both false positives and false negatives are accounted for, providing a better understanding of how well the model performs on each sentiment class."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb026b8",
      "metadata": {
        "id": "8cb026b8"
      },
      "source": [
        "## 0. LinearSVC with TF-IDF Features  \n",
        "\n",
        "We will now train a LinearSVC model using TF-IDF (Term Frequency-Inverse Document Frequency) as features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2e6298",
      "metadata": {
        "id": "ad2e6298"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(df_train[\"text\"])\n",
        "X_test_tfidf = vectorizer.transform(df_test[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9967a971",
      "metadata": {
        "id": "9967a971"
      },
      "outputs": [],
      "source": [
        "y_train = df_train[\"label\"]\n",
        "y_test = df_test[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcdbbec5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcdbbec5",
        "outputId": "20127b27-6af1-48d5-c5fc-63b639817dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (TF-IDF): 0.841747984726347\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85      1213\n",
            "           1       0.83      0.84      0.84      1144\n",
            "\n",
            "    accuracy                           0.84      2357\n",
            "   macro avg       0.84      0.84      0.84      2357\n",
            "weighted avg       0.84      0.84      0.84      2357\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = LinearSVC(random_state=42)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(\"Accuracy (TF-IDF):\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "411df717",
      "metadata": {
        "id": "411df717"
      },
      "source": [
        "The model's accuracy using TF-IDF is 0.8417 (84.17%) this our **baseline result**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1028a21b",
      "metadata": {
        "id": "1028a21b"
      },
      "source": [
        "## Task1: Text Preprocessing with spaCy\n",
        "\n",
        "Lemmatize original review texts with [spacy ](https://spacy.io/usage/linguistic-features#lemmatization)library.\n",
        "With spacy remove:\n",
        "\n",
        "*   stop words\n",
        "*   punctuation\n",
        "*   digits\n",
        "*   emails\n",
        "*   numbers\n",
        "*   empty word\n",
        "\n",
        "Train classifier with a new tf-idf representation of text. Obtain baseline classification metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc0fe2f6",
      "metadata": {
        "id": "bc0fe2f6"
      },
      "outputs": [],
      "source": [
        "#TODO function take text as an argument and return cleaned text\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        if not (token.is_stop or token.is_punct or token.is_digit or\n",
        "                token.like_email or token.is_space or token.like_num):\n",
        "            tokens.append(token.lemma_)\n",
        "\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bb510b1",
      "metadata": {
        "id": "8bb510b1"
      },
      "outputs": [],
      "source": [
        "df_train[\"text_lemmatized\"] = df_train[\"text\"].apply(clean_text)\n",
        "df_test[\"text_lemmatized\"] = df_test[\"text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29cf065",
      "metadata": {
        "id": "c29cf065"
      },
      "outputs": [],
      "source": [
        "# TODO get tf-idf vectors for your lemmatized texts\n",
        "X_train_tfidf_lemmatized = vectorizer.fit_transform(df_train[\"text_lemmatized\"])\n",
        "X_test_tfidf_lemmatized = vectorizer.transform(df_test[\"text_lemmatized\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a5e75a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a5e75a",
        "outputId": "79217bd2-d902-4286-9f98-daa2f2fd4ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (TF-IDF): 0.8413237165888842\n"
          ]
        }
      ],
      "source": [
        "model = LinearSVC(random_state=42)\n",
        "model.fit(X_train_tfidf_lemmatized, y_train)\n",
        "y_pred = model.predict(X_test_tfidf_lemmatized)\n",
        "print(\"Accuracy (TF-IDF):\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5itZ2DUtzUJ5",
      "metadata": {
        "id": "5itZ2DUtzUJ5"
      },
      "source": [
        "This is your **baseline** metrics!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72baffa9",
      "metadata": {
        "id": "72baffa9"
      },
      "source": [
        "## Task 2: Adding Part-of-Speech (POS) Features as a TF-IDF for Each POS Category\n",
        "\n",
        "For each text add part-of-speach (pos) tags as feature in TF-IDF manner. Use Spacy to get pos tag features. Combine them with lemmatized tf-idf features, obtained in the Task1.\n",
        "\n",
        "For example, if you have two sentences with following tf-idf vectors:\n",
        "\n",
        "1.   sent1: \"The cat sat on the mat.\" -> [0.63, 0.44, 0.31, 0.31, 0.44, 0, 0]\n",
        "2.   sent2: \"The dog sat on the floor. \" -> [0.63, 0, 0.31, 0.31, 0, 0.44, 0.44]\n",
        "\n",
        "And you obtained the following pos tag features (with dictionary {'det': 1, 'noun': 2, 'verb': 3, 'adp': 0}):\n",
        "\n",
        "*   sent1: [0.63, 0.63, 0.31, 0.31]\n",
        "*   sent2: [0.63, 0.63, 0.31, 0.31]\n",
        "\n",
        "\n",
        "Then final representation should be:\n",
        "\n",
        "*   sent1: [0.63, 0.44, 0.31, 0.31, 0.44, 0, 0, 0.63, 0.63, 0.31, 0.31]\n",
        "*   sent2: [0.63, 0, 0.31, 0.31, 0, 0.44, 0.44, 0.63, 0.63, 0.31, 0.31]\n",
        "\n",
        "**Note!** Do not use pos tags punctuation and empty words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KjuTut0a1Y9H",
      "metadata": {
        "id": "KjuTut0a1Y9H"
      },
      "outputs": [],
      "source": [
        "# TODO function takes text as input and return string with pos tags joined by a space.\n",
        "def extract_pos_tags(text):\n",
        "    doc = nlp(text)\n",
        "    pos_of_tokens = []\n",
        "    for token in doc:\n",
        "        if not (token.is_punct or token.is_space):\n",
        "            pos_of_tokens.append(token.pos_)\n",
        "\n",
        "    return ' '.join(pos_of_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0d0af0",
      "metadata": {
        "id": "1f0d0af0"
      },
      "outputs": [],
      "source": [
        "df_train[\"pos_text\"] = df_train[\"text\"].apply(extract_pos_tags)\n",
        "df_test[\"pos_text\"] = df_test[\"text\"].apply(extract_pos_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674b790b",
      "metadata": {
        "id": "674b790b"
      },
      "source": [
        "We need to bring the features obtained by CountVectorizer for POS tags to the same scale as TF-IDF. The easiest way is to apply TfidfTransformer to the CountVectorizer result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410ed982",
      "metadata": {
        "id": "410ed982"
      },
      "outputs": [],
      "source": [
        "#TODO train bag of words with pos tag features, then normalize them with TfidfTransformer, combine with X_train_tfidf_lemmatized\n",
        "# and X_test_tfidf_lemmatized features, save resulted features to the following variables:\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "\n",
        "count_vec = CountVectorizer()\n",
        "pos_count_vector_train = count_vec.fit_transform(df_train[\"pos_text\"])\n",
        "pos_count_vector_test = count_vec.transform(df_test[\"pos_text\"])\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "pos_count_vector_train = tfidf_transformer.fit_transform(pos_count_vector_train)\n",
        "pos_count_vector_test = tfidf_transformer.transform(pos_count_vector_test)\n",
        "\n",
        "X_train_combined = hstack([X_train_tfidf_lemmatized, pos_count_vector_train])\n",
        "X_test_combined = hstack([X_test_tfidf_lemmatized, pos_count_vector_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5b908f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e5b908f",
        "outputId": "e7540b5d-c394-467f-a100-af4629c99e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (tf-idf + POS): 0.8447178616885872\n"
          ]
        }
      ],
      "source": [
        "lr_combined = LinearSVC(random_state=42)\n",
        "lr_combined.fit(X_train_combined, y_train)\n",
        "y_pred_combined = lr_combined.predict(X_test_combined)\n",
        "\n",
        "print(\"Accuracy (tf-idf + POS):\", accuracy_score(y_test, y_pred_combined))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "378c0cd7",
      "metadata": {
        "id": "378c0cd7"
      },
      "source": [
        "## Task 3: Development of new features to improve classification accuracy\n",
        "\n",
        "Come up with another feature or set of features and help Alice improve the quality. Remember that Alice is in the past and does not have access to any . Additional training data cannot be used either. You can use third-party resources to generate features.\n",
        "\n",
        "Compare with result of your **baseline** from the Task 1. Any improvement will be counted. Use X_train_tfidf_lemmatized and X_test_tfidf_lemmatized, add combine your features with them as in task 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vSXv61eH4G9e",
      "metadata": {
        "id": "vSXv61eH4G9e"
      },
      "outputs": [],
      "source": [
        "# TODO create your features function here, add feature explanation\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def get_custom_feature(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = [token.text for token in doc]\n",
        "    negations = {\"not\", \"no\", \"never\", \"n't\"}\n",
        "    features = [\n",
        "        len(tokens),\n",
        "        len(text),\n",
        "        sum(1 for token in doc if token.is_stop),\n",
        "        sum(1 for token in doc if token.is_punct),\n",
        "        sum(1 for token in doc if token.is_digit),\n",
        "        sum(1 for token in doc if token.like_email),\n",
        "        sum(1 for token in doc if token.is_space),\n",
        "        sum(1 for token in doc if token.like_num),\n",
        "        sum(1 for ch in text if ch.isupper()),\n",
        "        sum(1 for ch in text if ch.islower()),\n",
        "        len(set(tokens)),\n",
        "        round(sum(len(token.text) for token in doc) / len(tokens), 4) if tokens else 0,\n",
        "        sum(1 for ch in text if not ch.isalnum() and not ch.isspace()),\n",
        "        sum(1 for token in doc if token.pos_ == \"ADJ\"),\n",
        "        sum(1 for token in doc if token.pos_ == \"ADV\"),\n",
        "        sum(1 for token in doc if token.pos_ == \"VERB\"),\n",
        "        sum(1 for token in doc if token.pos_ == \"NOUN\"),\n",
        "        sum(1 for token in doc if token.pos_ == \"SYM\"),\n",
        "        sum(1 for token in doc if token.lower_ in negations),\n",
        "        len(doc.ents),\n",
        "        text.count(\"!\"),\n",
        "        text.count(\"?\"),\n",
        "        text.count(\"$\"),\n",
        "        text.count(\":\"),\n",
        "        text.count(\".\"),\n",
        "        text.count(\",\")\n",
        "    ]\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "X_train_features = df_train[\"text\"].apply(get_custom_feature)\n",
        "X_test_features = df_test[\"text\"].apply(get_custom_feature)\n",
        "\n",
        "X_train_features_df = pd.DataFrame(X_train_features.tolist(), dtype=float)\n",
        "X_test_features_df = pd.DataFrame(X_test_features.tolist(), dtype=float)\n",
        "\n",
        "X_train_features_matrix = csr_matrix(X_train_features_df)\n",
        "X_test_features_matrix = csr_matrix(X_test_features_df)\n",
        "X_train_combined = hstack([X_train_tfidf_lemmatized, X_train_features_matrix])\n",
        "X_test_combined = hstack([X_test_tfidf_lemmatized, X_test_features_matrix])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4d8a6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb4d8a6b",
        "outputId": "b8190a18-278c-4c22-a806-ff6c7b77bf63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (tf-idf + Custom feature): 0.8599915146372508\n"
          ]
        }
      ],
      "source": [
        "lr_combined = LinearSVC(random_state=42, dual=False)\n",
        "lr_combined.fit(X_train_combined, y_train)\n",
        "y_pred_combined = lr_combined.predict(X_test_combined)\n",
        "\n",
        "print(\"Accuracy (tf-idf + Custom feature):\", accuracy_score(y_test, y_pred_combined))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}