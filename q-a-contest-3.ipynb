{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96803,"databundleVersionId":11502100,"sourceType":"competition"},{"sourceId":11288668,"sourceType":"datasetVersion","datasetId":6937810}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:03:14.659769Z","iopub.execute_input":"2025-04-05T19:03:14.660071Z","iopub.status.idle":"2025-04-05T19:03:14.664775Z","shell.execute_reply.started":"2025-04-05T19:03:14.660049Z","shell.execute_reply":"2025-04-05T19:03:14.663714Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(r'/kaggle/input/ioai-contest-3/train.csv')\ntest = pd.read_csv(r'/kaggle/input/ioai-contest-3/test.csv')\nextra = pd.read_csv(r'/kaggle/input/ioai-contest-3/extra_df.csv')\nsab = pd.read_csv(r'/kaggle/input/ioai-contest-3/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:03:16.408731Z","iopub.execute_input":"2025-04-05T19:03:16.409029Z","iopub.status.idle":"2025-04-05T19:03:16.537808Z","shell.execute_reply.started":"2025-04-05T19:03:16.409009Z","shell.execute_reply":"2025-04-05T19:03:16.536918Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"extra = extra.drop_duplicates()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:10:45.841700Z","iopub.execute_input":"2025-04-05T11:10:45.842038Z","iopub.status.idle":"2025-04-05T11:10:45.856522Z","shell.execute_reply.started":"2025-04-05T11:10:45.842013Z","shell.execute_reply":"2025-04-05T11:10:45.855261Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef get_context(model, df, extra, topn=1):\n    questions = [\"query: \" + q for q in df['questions'].tolist()]\n    passages = [\"passage: \" + t for t in extra['fact'].tolist()]\n    \n    question_embeds = model.encode(questions, convert_to_numpy=True, normalize_embeddings=True)\n    passage_embeds = model.encode(passages, convert_to_numpy=True, normalize_embeddings=True)\n\n    sim_matrix = cosine_similarity(question_embeds, passage_embeds)\n\n    topn_indices = np.argsort(-sim_matrix, axis=1)[:, :topn]\n\n    combined_contexts = []\n    similarities = []\n    \n    fact_lists = []\n    source_lists = []\n    category_lists = []\n    url_lists = []\n    author_lists = []\n    title_lists = []\n    \n    for i in range(len(df)):\n        indices = topn_indices[i]\n        topn_facts = extra.iloc[indices]['fact'].tolist()\n        sources = extra.iloc[indices]['source'].tolist()\n        categories = extra.iloc[indices]['category'].tolist()\n        urls = extra.iloc[indices]['url'].tolist()\n        authors = extra.iloc[indices]['author'].tolist()\n        titles = extra.iloc[indices]['title'].tolist()\n\n        combined_context = \" \".join(topn_facts)\n        combined_contexts.append(combined_context)\n        \n        max_sim = sim_matrix[i, indices[0]]\n        similarities.append(max_sim)\n        \n        # Append lists of extra fields\n        fact_lists.append(topn_facts)\n        source_lists.append(sources)\n        category_lists.append(categories)\n        url_lists.append(urls)\n        author_lists.append(authors)\n        title_lists.append(titles)\n\n    # Add the new columns to the dataframe\n    #df['combined_fact'] = combined_contexts\n    df['fact_list'] = fact_lists\n    df['source_list'] = source_lists\n    df['category_list'] = category_lists\n    df['url_list'] = url_lists\n    df['author_list'] = author_lists\n    df['title_list'] = title_lists\n    df['similarity'] = similarities\n\n    return df\n\n\ndef get_questions(model, train, test, topn=1):\n    # Prepare queries and passages\n    questions = [\"query: \" + q for q in test['questions'].tolist()]\n    passages = [\"passage: \" + t for t in train['questions'].tolist()]\n    \n    question_embeds = model.encode(questions, convert_to_numpy=True, normalize_embeddings=True)\n    passage_embeds = model.encode(passages, convert_to_numpy=True, normalize_embeddings=True)\n\n    sim_matrix = cosine_similarity(question_embeds, passage_embeds)\n\n    topn_indices = np.argsort(-sim_matrix, axis=1)[:, :topn + 1]\n\n    questions_contexts = []\n    targets_contexts = []\n    \n    for i in range(len(test)):\n        indices = topn_indices[i]\n        \n        if train.iloc[indices[0]]['questions'] == test.iloc[i]['questions']:\n            indices = indices[1:]\n        else:\n            indices = indices[:-1]\n        \n        questions_list = train.iloc[indices]['questions'].tolist()\n        answers_list = train.iloc[indices]['answer'].tolist()\n\n        questions_contexts.append(questions_list)\n        targets_contexts.append(answers_list)\n\n    test['near_questions'] = questions_contexts\n    test['near_answers'] = targets_contexts\n\n    return test\n\n\ndef get_chunks(model, df, extra, topn=1):\n    questions = [\"query: \" + q for q in df['questions'].tolist()]\n    passages = [\"passage: \" + t for t in extra['chunks'].tolist()]\n    \n    question_embeds = model.encode(questions, convert_to_numpy=True, normalize_embeddings=True)\n    passage_embeds = model.encode(passages, convert_to_numpy=True, normalize_embeddings=True)\n\n    sim_matrix = cosine_similarity(question_embeds, passage_embeds)\n\n    topn_indices = np.argsort(-sim_matrix, axis=1)[:, :topn]\n\n    list_chunks = []\n    \n    for i in range(len(df)):\n        indices = topn_indices[i]\n        topn_chunks = extra.iloc[indices]['chunks'].tolist()\n        \n        list_chunks.append(topn_chunks)\n\n    df['chunks'] = list_chunks\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:03:30.307334Z","iopub.execute_input":"2025-04-05T19:03:30.307645Z","iopub.status.idle":"2025-04-05T19:03:30.320837Z","shell.execute_reply.started":"2025-04-05T19:03:30.307622Z","shell.execute_reply":"2025-04-05T19:03:30.319845Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = SentenceTransformer('intfloat/e5-large-v2')\n\ntrain_with_extra = get_context(model, train, extra, topn=3)\ntest_with_extra = get_context(model, test, extra, topn=3)\n# train_with_extra = get_questions(model, train_with_extra, train_with_extra, topn=3)\n# test_with_extra = get_questions(model, train_with_extra, test_with_extra, topn=3)\n# train_with_chunks = get_chunks(model, train, url_chunks, topn=3)\n# test_with_chunks = get_chunks(model, test, url_chunks, topn=3)'\n'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:03:42.293338Z","iopub.execute_input":"2025-04-05T19:03:42.293638Z","iopub.status.idle":"2025-04-05T19:11:21.664404Z","shell.execute_reply.started":"2025-04-05T19:03:42.293616Z","shell.execute_reply":"2025-04-05T19:11:21.663681Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec2879bcddfc4023a13d2738d5f96558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/67.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"411fe77fd07d43c488962c45edcf01e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a66ad6f1224cbcada84ec77483561d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20732a3d369f4569ac45b5dcd7849fa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5898a4aa0b8743a5972cb3f6384c54cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f97dbfbd8a24adb8b1927d55a30f390"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4d866e687f42568c66f14e419c655b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1ab58dbed1543fba1afd45fde20849e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5662ee2c346401ab26b227d1b4f8515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b80c62ab822a4a99a79cf17cab9ab909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/62 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1047c27ded704ba69bde08481ffdd9b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aad2a3b824924807a142ed150d6888d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/27 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6c12d829184a02880bdfb3e8ee7d26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd2595a364442779cc6527a4232bf59"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_with_chunks.to_csv('train_with_extra.csv', index=False)\ntest_with_chunks.to_csv('test_with_extra.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:11:35.244506Z","iopub.execute_input":"2025-04-05T19:11:35.244801Z","iopub.status.idle":"2025-04-05T19:11:35.308042Z","shell.execute_reply.started":"2025-04-05T19:11:35.244779Z","shell.execute_reply":"2025-04-05T19:11:35.307111Z"}},"outputs":[],"execution_count":8}]}