{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["QRIy0Nzt67IZ"]},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#Preparing Data","metadata":{"id":"ItCJhRfkFJxJ"}},{"cell_type":"markdown","source":"Loading train and test data.","metadata":{"id":"wfJw7SZ4DN5x"}},{"cell_type":"code","source":"! wget -O task2_ru_training.tsv https://www.dropbox.com/s/2nvhmusyozfrrn9/train.tsv?dl=0\n! wget -O task2_ru_test.tsv https://www.dropbox.com/s/77s33v3q3q1i5mr/test.tsv?dl=0","metadata":{"id":"UWYIy8Z4DQ98","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b2868f5-3c47-4d01-ecc7-513d6f70955e","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:22.796512Z","iopub.execute_input":"2025-04-03T19:26:22.796950Z","iopub.status.idle":"2025-04-03T19:26:25.305786Z","shell.execute_reply.started":"2025-04-03T19:26:22.796906Z","shell.execute_reply":"2025-04-03T19:26:25.304681Z"}},"outputs":[{"name":"stdout","text":"--2025-04-03 19:26:22--  https://www.dropbox.com/s/2nvhmusyozfrrn9/train.tsv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fi/wwfpnhjsr6iav25qzc503/train.tsv?rlkey=oivvlhhxwi8wkyvbdumzyncki&dl=0 [following]\n--2025-04-03 19:26:23--  https://www.dropbox.com/scl/fi/wwfpnhjsr6iav25qzc503/train.tsv?rlkey=oivvlhhxwi8wkyvbdumzyncki&dl=0\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucda5cc49cc7ed037351897464b8.dl.dropboxusercontent.com/cd/0/inline/CnGU-7B5IsGUUbPX8WntNYbVBpIpyNSyfzlVWcYKzEoWYyW6mkacG0xquZhjo6beNxctX37TYF2ayxhUe0GSJ62EnV7fN7136cPbd_8UBuM6wNE8nywruN6ZFXO8zuWaCyg/file# [following]\n--2025-04-03 19:26:23--  https://ucda5cc49cc7ed037351897464b8.dl.dropboxusercontent.com/cd/0/inline/CnGU-7B5IsGUUbPX8WntNYbVBpIpyNSyfzlVWcYKzEoWYyW6mkacG0xquZhjo6beNxctX37TYF2ayxhUe0GSJ62EnV7fN7136cPbd_8UBuM6wNE8nywruN6ZFXO8zuWaCyg/file\nResolving ucda5cc49cc7ed037351897464b8.dl.dropboxusercontent.com (ucda5cc49cc7ed037351897464b8.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\nConnecting to ucda5cc49cc7ed037351897464b8.dl.dropboxusercontent.com (ucda5cc49cc7ed037351897464b8.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2201389 (2.1M) [text/plain]\nSaving to: ‘task2_ru_training.tsv’\n\ntask2_ru_training.t 100%[===================>]   2.10M  --.-KB/s    in 0.07s   \n\n2025-04-03 19:26:23 (29.3 MB/s) - ‘task2_ru_training.tsv’ saved [2201389/2201389]\n\n--2025-04-03 19:26:24--  https://www.dropbox.com/s/77s33v3q3q1i5mr/test.tsv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fi/8z5sccwbqc5ke5y83nw2m/test.tsv?rlkey=epavqzddx3cgg33026t0gzxyc&dl=0 [following]\n--2025-04-03 19:26:24--  https://www.dropbox.com/scl/fi/8z5sccwbqc5ke5y83nw2m/test.tsv?rlkey=epavqzddx3cgg33026t0gzxyc&dl=0\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucb2c1b3885244c2c2615c83cc5f.dl.dropboxusercontent.com/cd/0/inline/CnE4Fu8qkSBqiu7DoOd125eDZrzPAimkKy6VSOaj4Ibx6s8nStu9Q5Fc0yC254m-wm6xelWa7l0d-onzTb0q_A0HxRFNFki2uJ6g3phkv37Od0HKasM3ZmpQ1e98GMcVv0k/file# [following]\n--2025-04-03 19:26:24--  https://ucb2c1b3885244c2c2615c83cc5f.dl.dropboxusercontent.com/cd/0/inline/CnE4Fu8qkSBqiu7DoOd125eDZrzPAimkKy6VSOaj4Ibx6s8nStu9Q5Fc0yC254m-wm6xelWa7l0d-onzTb0q_A0HxRFNFki2uJ6g3phkv37Od0HKasM3ZmpQ1e98GMcVv0k/file\nResolving ucb2c1b3885244c2c2615c83cc5f.dl.dropboxusercontent.com (ucb2c1b3885244c2c2615c83cc5f.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\nConnecting to ucb2c1b3885244c2c2615c83cc5f.dl.dropboxusercontent.com (ucb2c1b3885244c2c2615c83cc5f.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 379309 (370K) [text/plain]\nSaving to: ‘task2_ru_test.tsv’\n\ntask2_ru_test.tsv   100%[===================>] 370.42K  --.-KB/s    in 0.04s   \n\n2025-04-03 19:26:25 (8.35 MB/s) - ‘task2_ru_test.tsv’ saved [379309/379309]\n\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"### Splitting train and dev sets into train, dev, and test","metadata":{"id":"aezYXyaP67G5"}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"2soYNev367G7","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:25.307353Z","iopub.execute_input":"2025-04-03T19:26:25.307696Z","iopub.status.idle":"2025-04-03T19:26:25.312023Z","shell.execute_reply.started":"2025-04-03T19:26:25.307670Z","shell.execute_reply":"2025-04-03T19:26:25.311247Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"train_path = r\"task2_ru_training.tsv\"\ntest_path = r\"task2_ru_test.tsv\"\nres_dataset_dir = r\"corpus_normalized/\"\nif not os.path.exists(res_dataset_dir):\n    os.makedirs(res_dataset_dir)","metadata":{"id":"EDa3bZ-767HK","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:25.313818Z","iopub.execute_input":"2025-04-03T19:26:25.314130Z","iopub.status.idle":"2025-04-03T19:26:25.329370Z","shell.execute_reply.started":"2025-04-03T19:26:25.314097Z","shell.execute_reply":"2025-04-03T19:26:25.328613Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"train_df = pd.read_csv(train_path, sep=\",\", encoding=\"utf-8\")\ntest_df = pd.read_csv(test_path, sep=\",\", encoding=\"utf-8\")\ntrain_df, dev_df, _, _ = \\\n    train_test_split(train_df, train_df, test_size=0.1, random_state=42)\n\ntrain_positive_class_df = train_df[train_df['class'] == 1]\ntrain_negative_class_df = train_df[train_df['class'] == 0]\nnum_positive_examples = train_positive_class_df.shape[0]\n# For training set, we take the same amount of positive and negative examples\ntrain_negative_class_df = train_negative_class_df.sample(num_positive_examples, )\n# Concatenating positive and negative examples and shuffling the training set\nclass_normalized_train_df = pd.concat([train_positive_class_df, train_negative_class_df]).sample(frac=1)\n\n\nout_train_path = os.path.join(res_dataset_dir, \"train.tsv\")\nout_test_path = os.path.join(res_dataset_dir, \"test.tsv\")\nout_dev_path = os.path.join(res_dataset_dir, \"dev.tsv\")\n\n# class_normalized_train_df.to_csv(out_train_path, sep=\"\\t\", encoding=\"utf-8\", index=False, )\ntrain_df.to_csv(out_train_path, sep=\"\\t\", encoding=\"utf-8\", index=False,)\ntest_df.to_csv(out_test_path, sep=\"\\t\", encoding=\"utf-8\", index=False)\ndev_df.to_csv(out_dev_path, sep=\"\\t\", encoding=\"utf-8\", index=False, )\n\nprint(train_df.shape)\nprint(dev_df.shape)","metadata":{"id":"j8_EdIpn67HV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"358ebd8a-e4ec-4d50-d6d8-147a52b8a68d","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:25.330740Z","iopub.execute_input":"2025-04-03T19:26:25.331005Z","iopub.status.idle":"2025-04-03T19:26:25.466164Z","shell.execute_reply.started":"2025-04-03T19:26:25.330983Z","shell.execute_reply":"2025-04-03T19:26:25.465169Z"}},"outputs":[{"name":"stdout","text":"(8563, 3)\n(952, 3)\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"### Preprocessing\n\nPreprocessing is adopted from:\n\nhttps://github.com/akutuzov/webvectors/blob/master/preprocessing/modular_processing/unify.py\n\nWe unify letters to decrease the size of dictionary. We also unify and remove all punctuation.","metadata":{"id":"QRIy0Nzt67IZ"}},{"cell_type":"code","source":"import re\ndef list_replace(search, replacement, text):\n    \"\"\"\n    Replaces all symbols of text which are present\n    in the search string with the replacement string.\n    \"\"\"\n    search = [el for el in search if el in text]\n    for c in search:\n        text = text.replace(c, replacement)\n    return text\n\ndef clean_text(text):\n\n    text = list_replace \\\n        ('\\u00AB\\u00BB\\u2039\\u203A\\u201E\\u201A\\u201C\\u201F\\u2018\\u201B\\u201D\\u2019', '\\u0022', text)\n\n    text = list_replace \\\n        ('\\u2012\\u2013\\u2014\\u2015\\u203E\\u0305\\u00AF', '\\u2003\\u002D\\u002D\\u2003', text)\n\n    text = list_replace('\\u2010\\u2011', '\\u002D', text)\n\n    text = list_replace \\\n            (\n            '\\u2000\\u2001\\u2002\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u200B\\u202F\\u205F\\u2060\\u3000',\n            '\\u2002', text)\n\n    text = re.sub('\\u2003\\u2003', '\\u2003', text)\n    text = re.sub('\\t\\t', '\\t', text)\n\n    text = list_replace \\\n            (\n            '\\u02CC\\u0307\\u0323\\u2022\\u2023\\u2043\\u204C\\u204D\\u2219\\u25E6\\u00B7\\u00D7\\u22C5\\u2219\\u2062',\n            '.', text)\n\n    text = list_replace('\\u2217', '\\u002A', text)\n\n    text = list_replace('…', '...', text)\n\n    text = list_replace('\\u00C4', 'A', text)\n    text = list_replace('\\u00E4', 'a', text)\n    text = list_replace('\\u00CB', 'E', text)\n    text = list_replace('\\u00EB', 'e', text)\n    text = list_replace('\\u1E26', 'H', text)\n    text = list_replace('\\u1E27', 'h', text)\n    text = list_replace('\\u00CF', 'I', text)\n    text = list_replace('\\u00EF', 'i', text)\n    text = list_replace('\\u00D6', 'O', text)\n    text = list_replace('\\u00F6', 'o', text)\n    text = list_replace('\\u00DC', 'U', text)\n    text = list_replace('\\u00FC', 'u', text)\n    text = list_replace('\\u0178', 'Y', text)\n    text = list_replace('\\u00FF', 'y', text)\n    text = list_replace('\\u00DF', 's', text)\n    text = list_replace('\\u1E9E', 'S', text)\n    # Removing punctuation\n    text = list_replace(',.[]{}()=+-−*&^%$#@!~;:§/\\|\\?\"\\n', ' ', text)\n    # Replacing all numbers with masks\n    text = list_replace('0123456789', 'x', text)\n\n    currencies = list \\\n            (\n            '\\u20BD\\u0024\\u00A3\\u20A4\\u20AC\\u20AA\\u2133\\u20BE\\u00A2\\u058F\\u0BF9\\u20BC\\u20A1\\u20A0\\u20B4\\u20A7\\u20B0\\u20BF\\u20A3\\u060B\\u0E3F\\u20A9\\u20B4\\u20B2\\u0192\\u20AB\\u00A5\\u20AD\\u20A1\\u20BA\\u20A6\\u20B1\\uFDFC\\u17DB\\u20B9\\u20A8\\u20B5\\u09F3\\u20B8\\u20AE\\u0192'\n        )\n\n    alphabet = list \\\n            (\n            '\\t\\r абвгдеёзжийклмнопрстуфхцчшщьыъэюяАБВГДЕЁЗЖИЙКЛМНОПРСТУФХЦЧШЩЬЫЪЭЮЯabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ')\n\n    allowed = set(currencies + alphabet)\n\n    cleaned_text = [sym for sym in text if sym in allowed]\n    cleaned_text = ''.join(cleaned_text)\n\n    return cleaned_text","metadata":{"id":"8atWRqxj67Ia","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:25.467536Z","iopub.execute_input":"2025-04-03T19:26:25.467839Z","iopub.status.idle":"2025-04-03T19:26:25.478226Z","shell.execute_reply.started":"2025-04-03T19:26:25.467813Z","shell.execute_reply":"2025-04-03T19:26:25.477210Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"train_path = r\"corpus_normalized/train.tsv\"\ndev_path = r\"corpus_normalized/dev.tsv\"\ntest_path = r\"corpus_normalized/test.tsv\"\n\n# Loading data\ntrain_df = pd.read_csv(train_path, sep='\\t', encoding=\"utf-8\",)\ndev_df = pd.read_csv(dev_path, sep='\\t', encoding=\"utf-8\",)\ntest_df = pd.read_csv(test_path, sep='\\t', encoding=\"utf-8\",)\n\n# Extracting tweet texts\ntrain_tweet_texts = train_df.tweet.values\ntest_tweet_texts = test_df.tweet.values\ndev_tweet_texts = dev_df.tweet.values\n\n# Preprocessing training tweets\ncleaned_train_texts = []\nfor tweet_text in train_tweet_texts:\n    cleaned_text = clean_text(tweet_text).lower()\n    split_cleaned_text = cleaned_text.split()\n    cleaned_train_texts.append(\" \".join(split_cleaned_text))\n\n# Preprocessing test tweets\ncleaned_test_texts = []\nfor tweet_text in test_tweet_texts:\n    cleaned_text = clean_text(tweet_text)\n    cleaned_test_texts.append(\" \".join(cleaned_text.split()))\n\n# Preprocessing validation tweets\ncleaned_dev_texts = []\nfor tweet_text in dev_tweet_texts:\n    cleaned_text = clean_text(tweet_text)\n    cleaned_dev_texts.append(\" \".join(cleaned_text.split()))\n\ntrain_df[\"clean_text\"] = cleaned_train_texts\ndev_df[\"clean_text\"] = cleaned_dev_texts\ntest_df[\"clean_text\"] = cleaned_test_texts","metadata":{"id":"y7A4Z8xQ67If","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:25.479356Z","iopub.execute_input":"2025-04-03T19:26:25.479715Z","iopub.status.idle":"2025-04-03T19:26:26.121163Z","shell.execute_reply.started":"2025-04-03T19:26:25.479678Z","shell.execute_reply":"2025-04-03T19:26:26.120433Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from collections import Counter\n\nCounter(train_df['class'])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pl5jJnRoV--D","outputId":"ee29cfaa-7197-4a25-e9c6-e7514d7d01bd","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:26.122078Z","iopub.execute_input":"2025-04-03T19:26:26.122332Z","iopub.status.idle":"2025-04-03T19:26:26.128782Z","shell.execute_reply.started":"2025-04-03T19:26:26.122310Z","shell.execute_reply":"2025-04-03T19:26:26.128027Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"Counter({1: 759, 0: 7804})"},"metadata":{}}],"execution_count":67},{"cell_type":"markdown","source":"### Модель","metadata":{"id":"DR-LZpf6rIJr"}},{"cell_type":"code","source":"#!pip install transformers","metadata":{"id":"P2yRF8jp1XY2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a4a40a37-b946-4bd1-cecf-9a40e05e5cb7","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:26.129582Z","iopub.execute_input":"2025-04-03T19:26:26.129813Z","iopub.status.idle":"2025-04-03T19:26:26.143917Z","shell.execute_reply.started":"2025-04-03T19:26:26.129781Z","shell.execute_reply":"2025-04-03T19:26:26.143326Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"id":"HahIap9b00AG","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:26.146327Z","iopub.execute_input":"2025-04-03T19:26:26.146556Z","iopub.status.idle":"2025-04-03T19:26:26.159436Z","shell.execute_reply.started":"2025-04-03T19:26:26.146536Z","shell.execute_reply":"2025-04-03T19:26:26.158787Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"PRE_TRAINED_MODEL_NAME = 'ai-forever/ruRoberta-large'\nBATCH_SIZE = 64\nEPOCHS = 5\nLEARNING_RATE=2e-5\nNUM_WARMUP_STEPS=0","metadata":{"id":"wCJpoamjsL0-","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:26.161372Z","iopub.execute_input":"2025-04-03T19:26:26.161607Z","iopub.status.idle":"2025-04-03T19:26:26.174265Z","shell.execute_reply.started":"2025-04-03T19:26:26.161575Z","shell.execute_reply":"2025-04-03T19:26:26.173439Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"n_classes = 2","metadata":{"id":"SNT_UYnYUXF_","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:26.175057Z","iopub.execute_input":"2025-04-03T19:26:26.175269Z","iopub.status.idle":"2025-04-03T19:26:26.190964Z","shell.execute_reply.started":"2025-04-03T19:26:26.175249Z","shell.execute_reply":"2025-04-03T19:26:26.190138Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"class TwitterClassifier(nn.Module):\n  def __init__(self, n_classes):\n    super(TwitterClassifier, self).__init__()\n    self.bert = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n\n  def forward(self, input_ids, attention_mask):\n    outputs = self.bert(input_ids=input_ids,\n                         attention_mask=attention_mask)\n    # last_hidden_state_cls = outputs[0][:, 0, :]\n    last_hidden_state_cls = outputs['pooler_output']\n    output = self.drop(last_hidden_state_cls)\n    return self.out(output)","metadata":{"id":"Noe485H_rL7Z","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:26.191802Z","iopub.execute_input":"2025-04-03T19:26:26.192043Z","iopub.status.idle":"2025-04-03T19:26:26.207920Z","shell.execute_reply.started":"2025-04-03T19:26:26.192023Z","shell.execute_reply":"2025-04-03T19:26:26.207086Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\ntrain_tokenized = [tokenizer.encode(x, add_special_tokens=True) for x in cleaned_train_texts]\ndev_tokenized = [tokenizer.encode(x, add_special_tokens=True) for x in cleaned_dev_texts]\ntest_tokenized = [tokenizer.encode(x, add_special_tokens=True) for x in cleaned_test_texts]","metadata":{"id":"_hzBWCjGKASQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"828d440b-81ea-4d8f-d3cf-2c8c3f6e2d4a","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:26.208767Z","iopub.execute_input":"2025-04-03T19:26:26.209082Z","iopub.status.idle":"2025-04-03T19:26:28.718719Z","shell.execute_reply.started":"2025-04-03T19:26:26.209030Z","shell.execute_reply":"2025-04-03T19:26:28.717649Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"# находим самое длинное предложение\ntrain_max_len = 0\nfor i in train_tokenized:\n    if len(i) > train_max_len:\n        train_max_len = len(i)\n\ndev_max_len = 0\nfor i in dev_tokenized:\n    if len(i) > dev_max_len:\n        dev_max_len = len(i)\n\ntest_max_len = 0\nfor i in test_tokenized:\n    if len(i) > test_max_len:\n        test_max_len = len(i)\n\nprint(train_max_len)\nprint(dev_max_len)\nprint(test_max_len)\n","metadata":{"id":"KgN2fRe0KCMy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"20d4c54e-2436-4e05-e723-395298e81dbe","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:28.719734Z","iopub.execute_input":"2025-04-03T19:26:28.719998Z","iopub.status.idle":"2025-04-03T19:26:28.727919Z","shell.execute_reply.started":"2025-04-03T19:26:28.719977Z","shell.execute_reply":"2025-04-03T19:26:28.727180Z"}},"outputs":[{"name":"stdout","text":"156\n120\n112\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"class TwitterDataset(Dataset):\n  def __init__(self, ids, tweets, targets, tokenizer, max_len):\n    self.ids = ids\n    self.tweets = tweets\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n\n  def __len__(self):\n    return len(self.tweets)\n\n  def __getitem__(self, item):\n    tweet = str(self.tweets[item])\n    target = self.targets[item]\n    id = self.ids[item]\n    encoding = self.tokenizer.encode_plus(\n      tweet,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n      truncation=True,\n    )\n    return {\n      'id': id,\n      'tweet_text': tweet,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","metadata":{"id":"0WdKhbed7XjS","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:28.728771Z","iopub.execute_input":"2025-04-03T19:26:28.729056Z","iopub.status.idle":"2025-04-03T19:26:28.746734Z","shell.execute_reply.started":"2025-04-03T19:26:28.729033Z","shell.execute_reply":"2025-04-03T19:26:28.746039Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, batch_size, max_len):\n  if \"label\" in df:\n    labels = df.label.to_numpy()\n  else:\n    labels = [0] * len(df)\n  ds = TwitterDataset(\n    ids = df.id,\n    tweets=df.clean_text,\n    targets=labels,\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4,\n  )","metadata":{"id":"PriOOpje-ykn","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:28.747481Z","iopub.execute_input":"2025-04-03T19:26:28.747686Z","iopub.status.idle":"2025-04-03T19:26:28.769243Z","shell.execute_reply.started":"2025-04-03T19:26:28.747668Z","shell.execute_reply":"2025-04-03T19:26:28.768322Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"print(test_df.columns)\ntrain_df = train_df.rename(columns={'class': 'label'})\ndev_df = dev_df.rename(columns={'class': 'label'})\nprint(train_df.shape)\nprint(dev_df.shape)\nprint(test_df.shape)\n\n\ntokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\ntrain_data_loader = create_data_loader(train_df, tokenizer, BATCH_SIZE, train_max_len)\ndev_data_loader = create_data_loader(dev_df, tokenizer, BATCH_SIZE, dev_max_len)\ntest_data_loader = create_data_loader(test_df, tokenizer, BATCH_SIZE, test_max_len)","metadata":{"id":"SjOKKKUgAzHt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f687cf43-8210-4842-d347-143bde531a14","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:28.770236Z","iopub.execute_input":"2025-04-03T19:26:28.770530Z","iopub.status.idle":"2025-04-03T19:26:30.020143Z","shell.execute_reply.started":"2025-04-03T19:26:28.770509Z","shell.execute_reply":"2025-04-03T19:26:30.019439Z"}},"outputs":[{"name":"stdout","text":"Index(['id', 'tweet', 'clean_text'], dtype='object')\n(8563, 4)\n(952, 4)\n(1504, 3)\n","output_type":"stream"}],"execution_count":77},{"cell_type":"markdown","source":"Model training","metadata":{"id":"SNCGGRUiwp1L"}},{"cell_type":"code","source":"import torch","metadata":{"id":"L47eigNpWqqn","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:30.021065Z","iopub.execute_input":"2025-04-03T19:26:30.021291Z","iopub.status.idle":"2025-04-03T19:26:30.025042Z","shell.execute_reply.started":"2025-04-03T19:26:30.021272Z","shell.execute_reply":"2025-04-03T19:26:30.024262Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"device='cpu'","metadata":{"id":"BgM8kke7DHl3","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:30.025794Z","iopub.execute_input":"2025-04-03T19:26:30.026104Z","iopub.status.idle":"2025-04-03T19:26:30.045356Z","shell.execute_reply.started":"2025-04-03T19:26:30.026082Z","shell.execute_reply":"2025-04-03T19:26:30.044444Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"n_classes = 2\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TwitterClassifier(n_classes)\nif torch.cuda.device_count() > 1:\n    model = torch.nn.DataParallel(model)\nmodel = model.to(device)","metadata":{"id":"r5QTi21xDOwM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9022e40-dfde-4a75-b93e-2670fc4c84ee","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:30.046324Z","iopub.execute_input":"2025-04-03T19:26:30.046623Z","iopub.status.idle":"2025-04-03T19:26:32.447878Z","shell.execute_reply.started":"2025-04-03T19:26:30.046583Z","shell.execute_reply":"2025-04-03T19:26:32.446652Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=int(0.05 * total_steps),\n  num_training_steps=total_steps\n)\nloss_fn = nn.CrossEntropyLoss().to(device)","metadata":{"id":"yTirMAKbwn2e","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:32.449373Z","iopub.execute_input":"2025-04-03T19:26:32.449759Z","iopub.status.idle":"2025-04-03T19:26:32.471627Z","shell.execute_reply.started":"2025-04-03T19:26:32.449712Z","shell.execute_reply":"2025-04-03T19:26:32.470860Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n  model = model.train()\n  losses = []\n  correct_predictions = 0\n  for d in tqdm(data_loader):\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"GgnONPoHuscw","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:32.472871Z","iopub.execute_input":"2025-04-03T19:26:32.473208Z","iopub.status.idle":"2025-04-03T19:26:32.479716Z","shell.execute_reply.started":"2025-04-03T19:26:32.473182Z","shell.execute_reply":"2025-04-03T19:26:32.478711Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n  losses = []\n  correct_predictions = 0\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(input_ids=input_ids,\n        attention_mask=attention_mask)\n      _, preds = torch.max(outputs, dim=1)\n      loss = loss_fn(outputs, targets)\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"TOYVwIHcy1zx","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:26:32.480630Z","iopub.execute_input":"2025-04-03T19:26:32.480913Z","iopub.status.idle":"2025-04-03T19:26:32.497839Z","shell.execute_reply.started":"2025-04-03T19:26:32.480863Z","shell.execute_reply":"2025-04-03T19:26:32.497191Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"from collections import defaultdict\nimport torch\n\nhistory = defaultdict(list)\n\nbest_accuracy = 0\nfor epoch in range(EPOCHS):\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\n  print('-' * 10)\n  train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer,\n    device, scheduler, len(train_df))\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n  val_acc, val_loss = eval_model(model, dev_data_loader, loss_fn, device, len(dev_df))\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)","metadata":{"id":"kakZPyMvzTTz","colab":{"base_uri":"https://localhost:8080/","height":742},"outputId":"684fa4e9-c489-46f4-e65a-b86e30d61178","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:36:50.606096Z","iopub.execute_input":"2025-04-03T19:36:50.606431Z","iopub.status.idle":"2025-04-03T19:53:32.448457Z","shell.execute_reply.started":"2025-04-03T19:36:50.606406Z","shell.execute_reply":"2025-04-03T19:53:32.447413Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/1\n----------\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/268 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n100%|██████████| 268/268 [08:05<00:00,  1.81s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train loss 0.15965431994661244 accuracy 0.9351862664953872\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Val   loss 0.17145735695958136 accuracy 0.9296218487394957\n\nEpoch 2/1\n----------\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/268 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n100%|██████████| 268/268 [08:03<00:00,  1.80s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train loss 0.1605597347187907 accuracy 0.9323835104519445\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Val   loss 0.17145735695958136 accuracy 0.9296218487394957\n\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"history['train_acc'] = [train_acc.cpu() for train_acc in history['train_acc']]\nhistory['val_acc'] = [val_acc.cpu() for val_acc in history['val_acc']]","metadata":{"id":"2kQoV5uoV-VK","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:34:54.913132Z","iopub.execute_input":"2025-04-03T19:34:54.913420Z","iopub.status.idle":"2025-04-03T19:34:54.918580Z","shell.execute_reply.started":"2025-04-03T19:34:54.913392Z","shell.execute_reply":"2025-04-03T19:34:54.917851Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.ylim([0, 1]);","metadata":{"id":"bsQxfe3Tz58T","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:34:54.919370Z","iopub.execute_input":"2025-04-03T19:34:54.919630Z","iopub.status.idle":"2025-04-03T19:34:55.176432Z","shell.execute_reply.started":"2025-04-03T19:34:54.919594Z","shell.execute_reply":"2025-04-03T19:34:55.175428Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":86},{"cell_type":"markdown","source":"### Calculating dev and test precision, recall, f1-score and ROC_AUC:","metadata":{"id":"Kms46cam67I_"}},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef get_predictions(model, data_loader):\n  model = model.eval()\n  tweet_ids = []\n  predictions = []\n  prediction_probs = []\n  real_values = []\n  with torch.no_grad():\n    for d in data_loader:\n      ids = d[\"id\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      outputs = F.softmax(model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      ))\n      _, preds = torch.max(outputs, dim=1)\n      tweet_ids.extend(ids)\n      predictions.extend(preds)\n      prediction_probs.extend(outputs)\n  predictions = torch.stack(predictions).cpu()\n  prediction_probs = torch.stack(prediction_probs).cpu()\n  return tweet_ids, predictions, prediction_probs","metadata":{"id":"_1uz-Ucwz-AN","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:34:55.180339Z","iopub.execute_input":"2025-04-03T19:34:55.180617Z","iopub.status.idle":"2025-04-03T19:34:55.186419Z","shell.execute_reply.started":"2025-04-03T19:34:55.180588Z","shell.execute_reply":"2025-04-03T19:34:55.185495Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report\n\ntweet_ids, predicted_dev_labels, prediction_probs = get_predictions(model,dev_data_loader)\ndev_labels = dev_df.label\ndev_precision = precision_score(dev_labels, predicted_dev_labels)\ndev_recall = recall_score(dev_labels, predicted_dev_labels)\ndev_f_measure = f1_score(dev_labels, predicted_dev_labels)\ndev_roc_auc = roc_auc_score(dev_labels, predicted_dev_labels)\nprint(f\"Dev:\\nPrecision: {dev_precision}\\n\"\n        f\"Recall: {dev_recall}\\n\"\n        f\"F-measure: {dev_f_measure}\\n\"\n        f\"ROC_AUC: {dev_roc_auc}\")\nprint(classification_report(dev_labels, predicted_dev_labels))","metadata":{"id":"gHppSc1b67JA","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:34:55.187517Z","iopub.execute_input":"2025-04-03T19:34:55.187738Z","iopub.status.idle":"2025-04-03T19:35:11.468971Z","shell.execute_reply.started":"2025-04-03T19:34:55.187719Z","shell.execute_reply":"2025-04-03T19:35:11.467988Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n<ipython-input-87-6dd398b3003a>:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  outputs = F.softmax(model(\n","output_type":"stream"},{"name":"stdout","text":"Dev:\nPrecision: 0.5652173913043478\nRecall: 0.3561643835616438\nF-measure: 0.43697478991596633\nROC_AUC: 0.6667056275032338\n              precision    recall  f1-score   support\n\n           0       0.95      0.98      0.96       879\n           1       0.57      0.36      0.44        73\n\n    accuracy                           0.93       952\n   macro avg       0.76      0.67      0.70       952\nweighted avg       0.92      0.93      0.92       952\n\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"tweet_ids, predicted_test_labels, prediction_probs = get_predictions(model, test_data_loader)\n\ndf_submit = pd.DataFrame(columns=[\"id\", \"class\"])\ndf_submit[\"id\"] = test_df['id'].values\n# df_submit[\"class\"] = [float(x[1]) for x in prediction_probs]\ndf_submit[\"class\"] = [x.item() for x in predicted_test_labels]\ndf_submit.to_csv(\"solution.csv\", sep=\",\", index=False)","metadata":{"id":"9O5TLAzABFb9","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:35:11.470086Z","iopub.execute_input":"2025-04-03T19:35:11.470463Z","iopub.status.idle":"2025-04-03T19:35:37.628378Z","shell.execute_reply.started":"2025-04-03T19:35:11.470428Z","shell.execute_reply":"2025-04-03T19:35:37.627434Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n<ipython-input-87-6dd398b3003a>:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  outputs = F.softmax(model(\n","output_type":"stream"}],"execution_count":89}]}